{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RayNCode/code_collab/blob/main/RandomForest_final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DKeCvbSzbNJh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "sklearn.set_config(display=\"diagram\")\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import combinations\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I did a trick. To accelerate the process I did the preprocessing in another notebook to get a csv file and therefore I skipped the imputer step. See Main_1 notebook to check the merge"
      ],
      "metadata": {
        "id": "_mAa-ogytc9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.read_csv('/content/X_Data.csv', low_memory=False)\n",
        "df = pd.read_csv('/content/target_data.csv')\n",
        "y = df['target'].copy()\n",
        "y = np.where(y == 'B', 1, 0)\n",
        "categorical_columns = final_df.select_dtypes(include=['object']).columns\n",
        "final_df['N1'] = final_df['N1'].astype(str).astype('object')\n",
        "final_df['N2'] = final_df['N2'].astype(str).astype('object')\n",
        "final_df['N3'] = final_df['N3'].astype(str).astype('object')\n",
        "final_df['Categorie'] = final_df['Categorie'].astype(str).astype('object')\n",
        "final_df['REG'] = final_df['REG'].astype(str).astype('object')\n",
        "final_df[categorical_columns] = final_df[categorical_columns].fillna(\"None\")\n",
        "X = final_df.copy()"
      ],
      "metadata": {
        "id": "Hr0sP1hAbU02"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
      ],
      "metadata": {
        "id": "omjLyBLbbx5G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing = make_column_transformer (\n",
        "    (OneHotEncoder(handle_unknown='ignore'), ['insee_code',\"is_student\", \"OCCUPATION_42\", \"ACTIVITY_TYPE\", \"household\", \"sex\", \"employer_category\", \"job_category\", \"Terms_of_emp\",\n",
        "                       \"Eco_sect\", \"Job_dep\", \"WORK_CONDITION\", \"work_description\",\"N3\", \"N2\", \"N1\", \"town_type\", \"dep\", \"Emp_contract\", \"Club\", \"Categorie\", 'REG']),\n",
        "    (OrdinalEncoder(), [\"Highest_degree\", \"EMPLOYEE_COUNT\"]),\n",
        "    remainder='passthrough')"
      ],
      "metadata": {
        "id": "vjwdpJ1Db513"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "max_features = ['log2', 'sqrt']\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Create the random grid\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': n_estimators,\n",
        "    'classifier__max_features': max_features,\n",
        "    'classifier__max_depth': max_depth,\n",
        "    'classifier__min_samples_split': min_samples_split,\n",
        "    'classifier__min_samples_leaf': min_samples_leaf,\n",
        "    'classifier__bootstrap': bootstrap\n",
        "}\n"
      ],
      "metadata": {
        "id": "69GH5eIqklHl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessing), # Remplacer par le préprocesseur réel\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "aYnkQVxEkPK1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_hyperparameters(pipeline, param_grid, X_train, y_train):\n",
        "    \"\"\"\n",
        "    This function tunes the hyperparameters of a classifier using GridSearchCV and cross-validation\n",
        "    and returns the best classifier model with the optimal hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the cross-validation object using StratifiedKFold to ensure the class distribution is the same across all the folds\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "    # Create the RandomizedSearch object\n",
        "    clf = RandomizedSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_distributions=param_grid,\n",
        "        cv=cv, scoring='accuracy',\n",
        "        n_iter=50,\n",
        "        n_jobs=-1, random_state=0,\n",
        "        verbose=2)\n",
        "\n",
        "    # Fit the GridSearchCV object to the training data\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best hyperparameters\n",
        "    print(\"Best hyperparameters:\\n\", clf.best_params_)\n",
        "\n",
        "    # Return best_estimator_ attribute which gives us the best model that has been fitted to the training data\n",
        "    return clf.best_estimator_\n"
      ],
      "metadata": {
        "id": "UFjX9F-NdD-q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfb_opt = tune_hyperparameters(pipeline, param_grid_rf, X_train, y_train)"
      ],
      "metadata": {
        "id": "8uGEjgiwGW1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_calculator(clf, X_test, y_test, model_name):\n",
        "    '''\n",
        "    This function calculates all desired performance metrics for a given model on test data.\n",
        "    '''\n",
        "    y_pred = clf.predict(X_test)\n",
        "    result = pd.DataFrame(data=[accuracy_score(y_test, y_pred),\n",
        "                                precision_score(y_test, y_pred, average='macro'),\n",
        "                                recall_score(y_test, y_pred, average='macro'),\n",
        "                                f1_score(y_test, y_pred, average='macro'),\n",
        "                                roc_auc_score(y_test, clf.predict_proba(X_test)[::,1], average='macro')],\n",
        "                          index=['Accuracy','Macro Precision','Macro Recall','Macro F1-score','Macro AUC'],\n",
        "                          columns = [model_name])\n",
        "\n",
        "    result = (result * 100).round(2).astype(str) + '%'\n",
        "    return result"
      ],
      "metadata": {
        "id": "-Qoi-qVveF_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluation(clf, X_train, X_test, y_train, y_test, model_name):\n",
        "    '''\n",
        "    This function provides a complete report of the model's performance including classification reports and confusion matrix\n",
        "    '''\n",
        "    # Set font scale\n",
        "    sns.set(font_scale=1.5)\n",
        "\n",
        "    # Generate classification report for training set\n",
        "    y_pred_train = clf.predict(X_train)\n",
        "    print(\"\\n\\t  Classification report for training set\")\n",
        "    print(\"-\"*55)\n",
        "    print(classification_report(y_train, y_pred_train))\n",
        "\n",
        "    # Generate classification report for test set\n",
        "    y_pred_test = clf.predict(X_test)\n",
        "    print(\"\\n\\t   Classification report for test set\")\n",
        "    print(\"-\"*55)\n",
        "    print(classification_report(y_test, y_pred_test))\n",
        "    print('\\n')\n",
        "\n",
        "    # Create figure and subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, dpi=90, figsize=(12, 5))\n",
        "\n",
        "    # Plot confusion matrix for test set\n",
        "    cmap = plt.cm.Purples  # Remplace 'purple_cmap' par 'cmap'\n",
        "\n",
        "    ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, colorbar=False, cmap=cmap, ax=ax1)\n",
        "    ax1.set_title('Confusion Matrix for Test Data')\n",
        "    ax1.grid(False)\n",
        "\n",
        "    # Report desired results as a summary in the form of a table\n",
        "    result = metrics_calculator(clf, X_test, y_test, model_name)\n",
        "    table = ax2.table(cellText=result.values, colLabels=result.columns, rowLabels=result.index, loc='center')\n",
        "    table.scale(0.6, 3.6)\n",
        "    table.set_fontsize(12)\n",
        "    ax2.axis('tight')\n",
        "    # Hide the axes\n",
        "    ax2.axis('off')\n",
        "    # set the title\n",
        "    ax2.set_title('{} Performance Summary on Test Data'.format(model_name), fontsize=18)\n",
        "    # Modify color\n",
        "    for key, cell in table.get_celld().items():\n",
        "        if key[0] == 0:\n",
        "          cell.set_color('purple')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yWW_hnKhQLGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_params = {'xgbclassifier__subsample': 0.9000000000000001,\n",
        "#               'xgbclassifier__scale_pos_weight': 0.8300000000000001,\n",
        "#               'xgbclassifier__reg_lambda': 0.08,\n",
        "#               'xgbclassifier__reg_alpha': 0.8,\n",
        "#               'xgbclassifier__n_estimators': 151,\n",
        "#               'xgbclassifier__min_child_weight': 3.279999999999994,\n",
        "#               'xgbclassifier__max_depth': 5, 'xgbclassifier__max_delta_step': 1.54,\n",
        "#               'xgbclassifier__learning_rate': 0.76,\n",
        "#               'xgbclassifier__gamma': 0.9980000000000002,\n",
        "#               'xgbclassifier__colsample_bytree': 0.7100000000000001,\n",
        "#               'xgbclassifier__colsample_bylevel': 0.9400000000000002}"
      ],
      "metadata": {
        "id": "1lk-Pln1tKCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(rfb_opt, X_train, X_test, y_train, y_test, 'Random Forest')"
      ],
      "metadata": {
        "id": "G9XCt8R-eUAI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}